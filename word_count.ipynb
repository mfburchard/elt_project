{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english') #ended up not being able to make this work for some reason so used a megalist i found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debate_name</th>\n",
       "      <th>debate_section</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "      <th>speaking_time_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Candidates, welcome. Vice President Biden, the...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Oh, they didnt miss anything. Its a long rac...</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Why are Senator Sanders and Mayor Buttigieg to...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Well, you know that with regard to Senator San...</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Senator Sanders, let me give you the chance to...</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  debate_name debate_section    speaker  \\\n",
       "0  New Hampshire Democratic Debate Transcript         Part 1  George S.   \n",
       "1  New Hampshire Democratic Debate Transcript         Part 1  Joe Biden   \n",
       "2  New Hampshire Democratic Debate Transcript         Part 1  George S.   \n",
       "3  New Hampshire Democratic Debate Transcript         Part 1  Joe Biden   \n",
       "4  New Hampshire Democratic Debate Transcript         Part 1  George S.   \n",
       "\n",
       "                                              speech  speaking_time_seconds  \n",
       "0  Candidates, welcome. Vice President Biden, the...                   18.0  \n",
       "1  Oh, they didnt miss anything. Its a long rac...                   36.0  \n",
       "2  Why are Senator Sanders and Mayor Buttigieg to...                    4.0  \n",
       "3  Well, you know that with regard to Senator San...                   41.0  \n",
       "4  Senator Sanders, let me give you the chance to...                   21.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv to pd dataframe\n",
    "debate = pd.read_csv('debate_transcripts.csv', encoding= 'unicode_escape')\n",
    "\n",
    "debate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Oh, they didnt miss anything. Its a long rac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Well, you know that with regard to Senator San...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Because Donald Trump lies all the time. It doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>I believe that the way we beat Trump is by hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Thats true. And thats the disappointment and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        candidate                                             speech\n",
       "1       Joe Biden  Oh, they didnt miss anything. Its a long rac...\n",
       "3       Joe Biden  Well, you know that with regard to Senator San...\n",
       "5  Bernie Sanders  Because Donald Trump lies all the time. It doe...\n",
       "6  Bernie Sanders  I believe that the way we beat Trump is by hav...\n",
       "8  Bernie Sanders  Thats true. And thats the disappointment and..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter for new hampshire debate, candidates only\n",
    "\n",
    "candidate_names = ['Joe Biden', 'Bernie Sanders', 'Andrew Yang', 'Pete Buttigieg', 'Elizabeth Warren', 'Amy Klobuchar', 'Tom Steyer']\n",
    "\n",
    "new_hamp = debate[debate['debate_name'] == 'New Hampshire Democratic Debate Transcript']\n",
    "clean_df = new_hamp[new_hamp['speaker'].isin(candidate_names)]\n",
    "\n",
    "#cleaning up\n",
    "clean_df = clean_df.drop(columns = ['debate_section', 'debate_name', 'speaking_time_seconds'])\n",
    "clean_df = clean_df.rename(columns={'speaker': 'candidate'})\n",
    "\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Bernie and I work together all the time. But I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>First, let me say America, its great to be ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Because Donald Trump lies all the time. It doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>Oh, Bernie and I have been friends for a long ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Oh, they didnt miss anything. Its a long rac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>Im not interested in the labels. Im not inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>I dont think theres any question, George, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             speech\n",
       "candidate                                                          \n",
       "Amy Klobuchar     Bernie and I work together all the time. But I...\n",
       "Andrew Yang       First, let me say America, its great to be ba...\n",
       "Bernie Sanders    Because Donald Trump lies all the time. It doe...\n",
       "Elizabeth Warren  Oh, Bernie and I have been friends for a long ...\n",
       "Joe Biden         Oh, they didnt miss anything. Its a long rac...\n",
       "Pete Buttigieg    Im not interested in the labels. Im not inte...\n",
       "Tom Steyer        I dont think theres any question, George, th..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#by candidate, combine all words spoken into single string\n",
    "\n",
    "#using groupby to merge on candidate\n",
    "merged = clean_df.groupby('candidate')['speech'].apply(' '.join)\n",
    "merged_df = pd.DataFrame(merged)\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>speech_without_stopwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>bernie and i work together all the time but i ...</td>\n",
       "      <td>bernie work time think going able divide divid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>first let me say america its great to be back ...</td>\n",
       "      <td>let say america great debate stage thank excit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>because donald trump lies all the time it does...</td>\n",
       "      <td>donald trump lies time matter donald trump say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>oh bernie and i have been friends for a long t...</td>\n",
       "      <td>bernie friends long time things common things ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>oh they didnt miss anything its a long race i ...</td>\n",
       "      <td>miss long race took hit iowa ill probably hit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>im not interested in the labels im not interes...</td>\n",
       "      <td>interested labels interested republicans going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>i dont think theres any question george that a...</td>\n",
       "      <td>think theres question george week theres real ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             speech  \\\n",
       "candidate                                                             \n",
       "Amy Klobuchar     bernie and i work together all the time but i ...   \n",
       "Andrew Yang       first let me say america its great to be back ...   \n",
       "Bernie Sanders    because donald trump lies all the time it does...   \n",
       "Elizabeth Warren  oh bernie and i have been friends for a long t...   \n",
       "Joe Biden         oh they didnt miss anything its a long race i ...   \n",
       "Pete Buttigieg    im not interested in the labels im not interes...   \n",
       "Tom Steyer        i dont think theres any question george that a...   \n",
       "\n",
       "                                           speech_without_stopwords  \n",
       "candidate                                                            \n",
       "Amy Klobuchar     bernie work time think going able divide divid...  \n",
       "Andrew Yang       let say america great debate stage thank excit...  \n",
       "Bernie Sanders    donald trump lies time matter donald trump say...  \n",
       "Elizabeth Warren  bernie friends long time things common things ...  \n",
       "Joe Biden         miss long race took hit iowa ill probably hit ...  \n",
       "Pete Buttigieg    interested labels interested republicans going...  \n",
       "Tom Steyer        think theres question george week theres real ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stopwords and punctuation \n",
    "\n",
    "merged_df['speech'] = merged_df['speech'].str.replace(r'[^\\w\\s]+', '')\n",
    "\n",
    "stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards']\n",
    "stopwords += ['again', 'against', 'all', 'almost', 'alone', 'along']\n",
    "stopwords += ['already', 'also', 'although', 'always', 'am', 'among']\n",
    "stopwords += ['amongst', 'amoungst', 'amount', 'an', 'and', 'another']\n",
    "stopwords += ['any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere']\n",
    "stopwords += ['are', 'around', 'as', 'at', 'back', 'be', 'became']\n",
    "stopwords += ['because', 'become', 'becomes', 'becoming', 'been']\n",
    "stopwords += ['before', 'beforehand', 'behind', 'being', 'below']\n",
    "stopwords += ['beside', 'besides', 'between', 'beyond', 'bill', 'both']\n",
    "stopwords += ['bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant']\n",
    "stopwords += ['co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de']\n",
    "stopwords += ['describe', 'detail', 'did', 'do', 'done', 'down', 'due']\n",
    "stopwords += ['during', 'each', 'eg', 'eight', 'either', 'eleven', 'else']\n",
    "stopwords += ['elsewhere', 'empty', 'enough', 'etc', 'even', 'ever']\n",
    "stopwords += ['every', 'everyone', 'everything', 'everywhere', 'except']\n",
    "stopwords += ['few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first']\n",
    "stopwords += ['five', 'for', 'former', 'formerly', 'forty', 'found']\n",
    "stopwords += ['four', 'from', 'front', 'full', 'further', 'get', 'give']\n",
    "stopwords += ['go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her']\n",
    "stopwords += ['here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers']\n",
    "stopwords += ['herself', 'him', 'himself', 'his', 'how', 'however']\n",
    "stopwords += ['hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed']\n",
    "stopwords += ['interest', 'into', 'is', 'it', 'its', 'itself', 'keep']\n",
    "stopwords += ['last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made']\n",
    "stopwords += ['many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine']\n",
    "stopwords += ['more', 'moreover', 'most', 'mostly', 'move', 'much']\n",
    "stopwords += ['must', 'my', 'myself', 'name', 'namely', 'neither', 'never']\n",
    "stopwords += ['nevertheless', 'next', 'nine', 'no', 'nobody', 'none']\n",
    "stopwords += ['noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of']\n",
    "stopwords += ['off', 'often', 'on','once', 'one', 'only', 'onto', 'or']\n",
    "stopwords += ['other', 'others', 'otherwise', 'our', 'ours', 'ourselves']\n",
    "stopwords += ['out', 'over', 'own', 'part', 'per', 'perhaps', 'please']\n",
    "stopwords += ['put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed']\n",
    "stopwords += ['seeming', 'seems', 'serious', 'several', 'she', 'should']\n",
    "stopwords += ['show', 'side', 'since', 'sincere', 'six', 'sixty', 'so']\n",
    "stopwords += ['some', 'somehow', 'someone', 'something', 'sometime']\n",
    "stopwords += ['sometimes', 'somewhere', 'still', 'such', 'system', 'take']\n",
    "stopwords += ['ten', 'than', 'that', 'the', 'their', 'them', 'themselves']\n",
    "stopwords += ['then', 'thence', 'there', 'thereafter', 'thereby']\n",
    "stopwords += ['therefore', 'therein', 'thereupon', 'these', 'they']\n",
    "stopwords += ['thick', 'thin', 'third', 'this', 'those', 'though', 'three']\n",
    "stopwords += ['three', 'through', 'throughout', 'thru', 'thus', 'to']\n",
    "stopwords += ['together', 'too', 'top', 'toward', 'towards', 'twelve']\n",
    "stopwords += ['twenty', 'two', 'un', 'under', 'until', 'up', 'upon']\n",
    "stopwords += ['us', 'very', 'via', 'was', 'we', 'well', 'were', 'what']\n",
    "stopwords += ['whatever', 'when', 'whence', 'whenever', 'where']\n",
    "stopwords += ['whereafter', 'whereas', 'whereby', 'wherein', 'whereupon']\n",
    "stopwords += ['wherever', 'whether', 'which', 'while', 'whither', 'who']\n",
    "stopwords += ['whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with']\n",
    "stopwords += ['within', 'without', 'would', 'yet', 'you', 'your']\n",
    "stopwords += ['yours', 'yourself', 'yourselves']\n",
    "stopwords += ['doesnt', 'dont', 'oh', 'lot', 'im', 'didnt']\n",
    "\n",
    "test = merged_df\n",
    "test['speech'] = test['speech'].str.lower() \n",
    "\n",
    "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "test['speech_without_stopwords'] = test['speech'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "\n",
    "test = pd.DataFrame(test)\n",
    "\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                             speech  \\\n",
      "candidate                                                             \n",
      "Amy Klobuchar     bernie and i work together all the time but i ...   \n",
      "Andrew Yang       first let me say america its great to be back ...   \n",
      "Bernie Sanders    because donald trump lies all the time it does...   \n",
      "Elizabeth Warren  oh bernie and i have been friends for a long t...   \n",
      "Joe Biden         oh they didnt miss anything its a long race i ...   \n",
      "Pete Buttigieg    im not interested in the labels im not interes...   \n",
      "Tom Steyer        i dont think theres any question george that a...   \n",
      "\n",
      "                                           speech_without_stopwords  \\\n",
      "candidate                                                             \n",
      "Amy Klobuchar     bernie work time think going able divide divid...   \n",
      "Andrew Yang       let say america great debate stage thank excit...   \n",
      "Bernie Sanders    donald trump lies time matter donald trump say...   \n",
      "Elizabeth Warren  bernie friends long time things common things ...   \n",
      "Joe Biden         miss long race took hit iowa ill probably hit ...   \n",
      "Pete Buttigieg    interested labels interested republicans going...   \n",
      "Tom Steyer        think theres question george week theres real ...   \n",
      "\n",
      "                                                        speech_buzz  \n",
      "candidate                                                            \n",
      "Amy Klobuchar     bernie bernie republicans donald trumps middle...  \n",
      "Andrew Yang       america capitalism economic corporate substanc...  \n",
      "Bernie Sanders    donald trump donald trump joe elizabeth amy do...  \n",
      "Elizabeth Warren  bernie republicans government drug companies c...  \n",
      "Joe Biden         bernie senators middle class sanders senate be...  \n",
      "Pete Buttigieg    republicans politics donald trump politics pol...  \n",
      "Tom Steyer        donald trump bernie sanders black community la...  \n"
     ]
    }
   ],
   "source": [
    "#filter by buzzwords\n",
    "#buzzword categories\n",
    "candidates = ['bernie', 'elizabeth', 'pete', 'klobuchar', 'sanders', 'yang', 'campaign', 'joe', 'amy', 'biden']\n",
    "healthcare = ['health', 'insurance', 'heathcare', 'addiction', 'drugs', 'drug', 'treatment', 'opiods', \n",
    "              'opiod', 'opioids', 'substance', 'opioid', 'opiate', ]\n",
    "education = ['school', 'college', 'preschool', 'education']\n",
    "social = ['middle', 'americans', 'america', 'childcare', 'policy', 'women', 'abortions', 'baby', 'african', 'kids', \n",
    "         'communities', 'racism', 'community', 'familys', 'family', 'child', 'families', 'black', 'latinos', \n",
    "         'children', 'racist', 'whites']\n",
    "financial = ['economic', 'tax', 'workers', 'money', 'union', 'poverty', 'billionaire', 'paycheck', 'capitalism', 'corporate', \n",
    "            'job', 'jobs', 'taxes', 'companies', 'dollars', 'income', 'economy', 'businesses', 'class', 'billionaires', \n",
    "             'corporations', 'spending', 'housing', 'rich']\n",
    "international = ['canada', 'trade', 'mexico', 'allies', 'china', 'world', 'nato', 'international', 'russia', 'iraq', \n",
    "                 'afghanistan', 'iran']\n",
    "defense = ['security', 'military', 'weapons', 'war', 'troops', 'terrorism']\n",
    "politics = ['republicans', 'donald', 'trumps', 'republican', 'trump', 'senate', 'impeachment', 'washington', 'politics', \n",
    "            'constitutional', 'democrat', 'senators', 'obama', 'political', 'government', 'democracy', 'corruption', 'congress'\n",
    "           'constitution', 'clinton', 'policies', 'democrat']\n",
    "legal = ['courts', 'jail', 'court', 'criminal', 'gun', 'roe', 'abortions', 'shootings', 'violence', 'supreme', 'ban', \n",
    "         'incarceration', 'prisons', 'disproportionate', 'bail', 'guns', 'abortion']\n",
    "environment = ['climate', 'fossil', 'earth', 'environmental']\n",
    "\n",
    "buzz = candidates + healthcare + education + social + financial + international + defense + politics + legal + environment\n",
    "\n",
    "filtered = test\n",
    "\n",
    "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "filtered['speech_buzz'] = filtered['speech_without_stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word in (buzz)]))\n",
    "\n",
    "print(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count words by category\n",
    "\n",
    "filtered['candidates'] = filtered['speech_buzz'].apply(lambda x: ' '.join([word for word in x.split() if word in (candidates)]))\n",
    "candidates_count = filtered['candidates'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "filtered['healthcare'] = filtered['speech_buzz'].apply(lambda x: ' '.join([word for word in x.split() if word in (healthcare)]))\n",
    "healthcare_count = filtered['healthcare'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "filtered['education'] = filtered['speech_buzz'].apply(lambda x: ' '.join([word for word in x.split() if word in (education)]))\n",
    "education_count = filtered['education'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "filtered['social'] = filtered['speech_buzz'].apply(lambda x: ' '.join([word for word in x.split() if word in (social)]))\n",
    "social_count = filtered['social'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "filtered['financial'] = filtered['speech_buzz'].apply(lambda x: ' '.join([word for word in x.split() if word in (financial)]))\n",
    "financial_count = filtered['financial'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "filtered['international'] = filtered['speech_buzz'].apply(lambda x: ' '.join([word for word in x.split() if word in (international)]))\n",
    "international_count = filtered['international'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "filtered['defense'] = filtered['speech_buzz'].apply(lambda x: ' '.join([word for word in x.split() if word in (defense)]))\n",
    "defense_count = filtered['defense'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "filtered['politics'] = filtered['speech_buzz'].apply(lambda x: ' '.join([word for word in x.split() if word in (politics)]))\n",
    "politics_count = filtered['politics'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "filtered['legal'] = filtered['speech_buzz'].apply(lambda x: ' '.join([word for word in x.split() if word in (legal)]))\n",
    "legal_count = filtered['legal'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "filtered['environment'] = filtered['speech_buzz'].apply(lambda x: ' '.join([word for word in x.split() if word in (environment)]))\n",
    "environment_count = filtered['environment'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>democratic_primary</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>education</th>\n",
       "      <th>social_issues</th>\n",
       "      <th>economy_finance</th>\n",
       "      <th>international_relations</th>\n",
       "      <th>politics</th>\n",
       "      <th>legal_justice</th>\n",
       "      <th>environment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  democratic_primary  healthcare  education  social_issues  \\\n",
       "candidate                                                                    \n",
       "Amy Klobuchar                     13          14          4             26   \n",
       "Andrew Yang                        4           9          3             39   \n",
       "Bernie Sanders                    24          14          3             34   \n",
       "Elizabeth Warren                   5           6          7             48   \n",
       "Joe Biden                         17           8         11             46   \n",
       "Pete Buttigieg                     6          17          1             29   \n",
       "Tom Steyer                        24           1          3             44   \n",
       "\n",
       "                  economy_finance  international_relations  politics  \\\n",
       "candidate                                                              \n",
       "Amy Klobuchar                  18                       22        29   \n",
       "Andrew Yang                    32                        2        10   \n",
       "Bernie Sanders                 50                       22        42   \n",
       "Elizabeth Warren               36                       12        34   \n",
       "Joe Biden                      19                       25        18   \n",
       "Pete Buttigieg                 24                       12        39   \n",
       "Tom Steyer                     26                       15        30   \n",
       "\n",
       "                  legal_justice  environment  \n",
       "candidate                                     \n",
       "Amy Klobuchar                 6            5  \n",
       "Andrew Yang                   3            1  \n",
       "Bernie Sanders               22           17  \n",
       "Elizabeth Warren             22            3  \n",
       "Joe Biden                    20            1  \n",
       "Pete Buttigieg               13            1  \n",
       "Tom Steyer                    7            5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new dataframe with candidate and count of words for each category\n",
    "\n",
    "dict = {'democratic_primary': candidates_count, \n",
    "        'healthcare': healthcare_count, \n",
    "        'education' : education_count, \n",
    "        'social_issues' : social_count, \n",
    "        'economy_finance' : financial_count, \n",
    "        'international_relations' : international_count, \n",
    "        'politics' : politics_count, \n",
    "        'legal_justice' : legal_count,\n",
    "        'environment' : environment_count}\n",
    "\n",
    "shiny_df = pd.DataFrame(dict)\n",
    "shiny_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>democratic_primary</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>education</th>\n",
       "      <th>social_issues</th>\n",
       "      <th>economy_finance</th>\n",
       "      <th>international_relations</th>\n",
       "      <th>politics</th>\n",
       "      <th>legal_justice</th>\n",
       "      <th>environment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th>candidate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Biden</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Buttigieg</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Klobuchar</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sanders</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Steyer</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Warren</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Yang</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        democratic_primary  healthcare  education  \\\n",
       "candidate_id candidate                                              \n",
       "1            Biden                      17           8         11   \n",
       "2            Buttigieg                   6          17          1   \n",
       "3            Klobuchar                  13          14          4   \n",
       "4            Sanders                    24          14          3   \n",
       "5            Steyer                     24           1          3   \n",
       "6            Warren                      5           6          7   \n",
       "7            Yang                        4           9          3   \n",
       "\n",
       "                        social_issues  economy_finance  \\\n",
       "candidate_id candidate                                   \n",
       "1            Biden                 46               19   \n",
       "2            Buttigieg             29               24   \n",
       "3            Klobuchar             26               18   \n",
       "4            Sanders               34               50   \n",
       "5            Steyer                44               26   \n",
       "6            Warren                48               36   \n",
       "7            Yang                  39               32   \n",
       "\n",
       "                        international_relations  politics  legal_justice  \\\n",
       "candidate_id candidate                                                     \n",
       "1            Biden                           25        18             20   \n",
       "2            Buttigieg                       12        39             13   \n",
       "3            Klobuchar                       22        29              6   \n",
       "4            Sanders                         22        42             22   \n",
       "5            Steyer                          15        30              7   \n",
       "6            Warren                          12        34             22   \n",
       "7            Yang                             2        10              3   \n",
       "\n",
       "                        environment  \n",
       "candidate_id candidate               \n",
       "1            Biden                1  \n",
       "2            Buttigieg            1  \n",
       "3            Klobuchar            5  \n",
       "4            Sanders             17  \n",
       "5            Steyer               5  \n",
       "6            Warren               3  \n",
       "7            Yang                 1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning up and final version\n",
    "\n",
    "word_count_df = shiny_df.reset_index()\n",
    "\n",
    "word_count_df[['first_name','last_name']] = word_count_df['candidate'].loc[word_count_df['candidate'].str.split().str.len() == 2].str.split(expand=True)\n",
    "\n",
    "word_count_df = word_count_df.drop(columns = ['candidate', 'first_name'])\n",
    "\n",
    "word_count_df = word_count_df.rename(columns = {'last_name' : 'candidate'})\n",
    "\n",
    "word_count_df = word_count_df.sort_values(by = ['candidate'])\n",
    "\n",
    "word_count_df['candidate_id'] = [1,2,3,4,5,6,7]\n",
    "\n",
    "word_count_df = word_count_df.set_index(['candidate_id','candidate'])\n",
    "\n",
    "word_count_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df.to_csv('Final/word_count.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
